---
title: "data_cleaning"
author: "Geena Kim"
date: "12/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(naniar)
library(gt)
```

```{r load_data}

# Read in the raw data, specifying each variable's type
crime_data <- read_csv('shiny/NYPD_crime_data.csv',
                       col_types = cols(
                         .default = col_character(),
                         CMPLNT_NUM = col_double(),
                         ADDR_PCT_CD = col_double(),
                         CMPLNT_FR_TM = col_time(format = ""),
                         CMPLNT_TO_TM = col_time(format = ""),
                         HOUSING_PSA = col_double(),
                         JURISDICTION_CODE = col_double(),
                         KY_CD = col_double(),
                         PD_CD = col_double(),
                         TRANSIT_DISTRICT = col_double(),
                         X_COORD_CD = col_double(),
                         Y_COORD_CD = col_double(),
                         Latitude = col_double(),
                         Longitude = col_double())) %>%
  clean_names() %>%
  filter(juris_desc == "N.Y. POLICE DEPT") %>%
  select(cmplnt_num,law_cat_cd, ofns_desc, pd_desc,
         susp_race, susp_age_group, susp_sex, vic_race, vic_age_group, vic_sex,
         boro_nm, parks_nm, prem_typ_desc,cmplnt_to_dt, cmplnt_to_tm,
         crm_atpt_cptd_cd)

# Take a look at your data by running the below code. There's more information
# regarding this data in raw_data/data_info

# glimpse(raw_data)
# summary(raw_data)
# head(raw_data, 10)

```

```{r clean_data}

# Executed the below code to determine which Na values I should drop vs which 
# columns I should just entirely drop.
# colSums(is.na(data))

# There was only one observation where vic_age_group was NA. This same
# observation was the only NA value in vic_race and vic_sex as well, so I
# dropped this individual NA observation.

colSums(is.na(data))

```


```{r}
set.seed(30)

# Set the seed for consistent output
# Convert date-time into a numeric after rounding by the hour

        model_data <- crime_data %>%
            select(law_cat_cd, cmplnt_to_tm) %>%
            drop_na() %>%
            mutate(time_chr = as.character(cmplnt_to_tm)) %>%
            mutate(time_sub = map_chr(time_chr, ~ substr(., 1, 2))) %>%
            mutate(time_numeric = as.numeric(time_sub)) %>%
            select(law_cat_cd, time_numeric)
        
        fitted_model <- model_data %>%
            stan_glm(formula = time_numeric ~ law_cat_cd - 1,
                     family = gaussian(),
                     refresh = 0)
        
        # I created a posterior distribution below.
        
        fitted_model %>% 
            as_tibble() %>% 
            select(-sigma) %>% 
            mutate(Felony = law_cat_cdFELONY, 
                   Misdemeanor = law_cat_cdMISDEMEANOR, 
                   Violation = law_cat_cdVIOLATION) %>%
            pivot_longer(cols = Felony:Violation,
                         names_to = "parameter",
                         values_to = "time") %>% 
            ggplot(aes(x = time, fill = parameter)) +
            geom_histogram(aes(y = after_stat(count/sum(count))),
                           alpha = 0.8, 
                           bins = 120, 
                           position = "identity",
                           color = "darkgrey") +
            labs(title = "Posterior Probability Distribution",
                 subtitle = "Average time of Crimes in NYC 2019 to 2020",
                 x = "Time",
                 y = "Probability") +
            scale_fill_manual(name = "Level of Offense",
                              labels = c("Felony", "Misdemeanor", "Violation"),
                              values = c("steelblue", "cadetblue3", "azure3")) +
            scale_y_continuous(labels = scales::percent_format()) +
            theme_classic()
        
print(fitted_model, digits = 5)
```

```{r}

# Gives the count of all the different types of crimes committed
# Pipe the data into arrange to see the top reported crimes

crime_data %>%
  select(law_cat_cd, ofns_desc) %>%
  group_by(ofns_desc, law_cat_cd) %>%
  summarise(count = n()) %>%
  arrange(desc(count))
```


```{r}

# Create a gt table with the stan_glm data

tibble(subject = c("Violation", "Misdemeanor ", "Violation"),
       Median = c("12.49758", "13.02425", "13.89109"),
       MAD_SD = c("0.02299", "0.01713", "0.03295")) %>%
    
    # table setup
  
    gt() %>%
    cols_label(subject = "Model",
               Median = "Median",
               MAD_SD = "MAD_SD") %>%
    tab_style(cell_borders(sides = "right"),
              location = cells_body(columns = vars(subject))) %>%
    tab_style(cell_text(weight = "bold"),
              location = cells_body(columns = vars(subject))) %>%
    cols_align(align = "center", columns = TRUE) %>%
    fmt_markdown(columns = TRUE) 

```

